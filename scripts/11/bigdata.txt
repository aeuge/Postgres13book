-- creating 2 core 4 GB 100 ssd for big data
gcloud beta compute --project=celtic-house-266612 instances create postgres13bd --zone=us-central1-a --machine-type=e2-medium --subnet=default --network-tier=PREMIUM --maintenance-policy=MIGRATE --service-account=933982307116-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/cloud-platform --image=ubuntu-minimal-2004-focal-v20210416 --image-project=ubuntu-os-cloud --boot-disk-size=100GB --boot-disk-type=pd-ssd --boot-disk-device-name=postgres13bd --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any

bq show bigquery-public-data:chicago_taxi_trips.taxi_trips
bq extract bigquery-public-data:chicago_taxi_trips.taxi_trips gs://pg2021/chicago/taxi.csv.*

SELECT count(*)
FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`;

SELECT payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c
FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` 
group by payment_type
order by 3 desc;



create extension file_fdw;
create server pgcsv foreign data wrapper file_fdw;

create foreign table taxi_trips_fdw_2 (
unique_key text, 
taxi_id text, 
trip_start_timestamp TIMESTAMP, 
trip_end_timestamp TIMESTAMP, 
trip_seconds bigint, 
trip_miles numeric, 
pickup_census_tract bigint, 
dropoff_census_tract bigint, 
pickup_community_area bigint, 
dropoff_community_area bigint, 
fare numeric, 
tips numeric, 
tolls numeric, 
extras numeric, 
trip_total numeric, 
payment_type text, 
company text, 
pickup_latitude numeric, 
pickup_longitude numeric, 
pickup_location text, 
dropoff_latitude numeric, 
dropoff_longitude numeric, 
dropoff_location text
)
server pgcsv
options(filename '/tmp/taxi_trips_2020_10/taxi_trip_000000000200.csv', format 'csv', header 'true', delimiter ',');

COPY product(title, department) FROM PROGRAM 'awk FNR-1 ys*.csv | cat' DELIMITER ',' CSV HEADER;

\copy taxi_trips from program 'awk FNR-1 /opt/taxi_trips/*.csv | cat' with format csv, header true

SELECT payment_type, round(sum(tips)/sum(trip_total)*100, 0) as tips_percent, count(*) as c
FROM taxi_trips
group by payment_type
order by 3;


COPY taxi_trips(unique_key, 
taxi_id, 
trip_start_timestamp, 
trip_end_timestamp, 
trip_seconds, 
trip_miles, 
pickup_census_tract, 
dropoff_census_tract, 
pickup_community_area, 
dropoff_community_area, 
fare, 
tips, 
tolls, 
extras, 
trip_total, 
payment_type, 
company, 
pickup_latitude, 
pickup_longitude, 
pickup_location, 
dropoff_latitude, 
dropoff_longitude, 
dropoff_location)
FROM PROGRAM 'awk FNR-1 /tmp/taxi_trips_2020_10/*.csv | cat' DELIMITER ',' CSV HEADER;

create table taxi_trips (
unique_key text, 
taxi_id text, 
trip_start_timestamp TIMESTAMP, 
trip_end_timestamp TIMESTAMP, 
trip_seconds bigint, 
trip_miles numeric, 
pickup_census_tract bigint, 
dropoff_census_tract bigint, 
pickup_community_area bigint, 
dropoff_community_area bigint, 
fare numeric, 
tips numeric, 
tolls numeric, 
extras numeric, 
trip_total numeric, 
payment_type text, 
company text, 
pickup_latitude numeric, 
pickup_longitude numeric, 
pickup_location text, 
dropoff_latitude numeric, 
dropoff_longitude numeric, 
dropoff_location text
);

for f in /tmp/taxi_trips_2020_10/taxi*
do
	echo -e "Processing $f file..."
	psql "host=mpp-test-c.postgres.database.azure.com port=5432 dbname=citus user=citus sslmode=require" -c "\\COPY taxi_trips FROM PROGRAM 'cat $f' CSV HEADER"
done

SELECT create_distributed_table('taxi_trips', 'taxi_id');

gsutil -m cp -R gs://taxi_trips_2020_10 .